{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EOL0AvaDFeQP"
      },
      "outputs": [],
      "source": [
        "import gensim.utils as utils\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from nltk.tokenize import word_tokenize\n",
        "import sentencepiece as spm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mlV7Z8NHFeQU"
      },
      "outputs": [],
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, corpus_length = None, device = None, corpus_path = './data/train_shuf.txt'):\n",
        "        corpus_file = open(corpus_path)\n",
        "\n",
        "        if device == None:\n",
        "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        if corpus_length == None:\n",
        "            corpus_length = sum(1 for line in corpus_file)\n",
        "            corpus_file.seek(0)\n",
        "        \n",
        "        self.corpus = []\n",
        "\n",
        "        for i in tqdm(range(corpus_length)):\n",
        "            self.corpus.append(utils.simple_preprocess(corpus_file.readline(), min_len=1))\n",
        "            # self.corpus.append(word_tokenize(corpus_file.readline().lower()))\n",
        "\n",
        "        self.corpus = sorted(self.corpus, key=lambda x: len(x))\n",
        "        \n",
        "        self.unique_words = self.get_unique_words()\n",
        "\n",
        "        self.index_to_word = {index: word for index, word in enumerate(self.unique_words)}\n",
        "        self.word_to_index = {word: index for index, word in enumerate(self.unique_words)}\n",
        "\n",
        "        self.input_corpus_indexes = [list(map(lambda word: self.word_to_index[word], sentence)) for sentence in self.corpus]\n",
        "        output_corpus = [sentence[1:] + ['<STOP>'] for sentence in self.corpus]\n",
        "\n",
        "        self.output_corpus_indexes = [list(map(lambda word: self.word_to_index[word], sentence)) for sentence in output_corpus]\n",
        "        \n",
        "        self.device = device\n",
        "\n",
        "\n",
        "    def indexes_to_sentence(self, sentence):\n",
        "        return list(map(lambda x: self.index_to_word[x], sentence))\n",
        "\n",
        "\n",
        "    def get_unique_words(self):\n",
        "        words = list(set([word for line in self.corpus for word in line]))\n",
        "        words.sort()\n",
        "        words = ['<PAD>', '<STOP>'] + words\n",
        "        self.pad_index = 0\n",
        "        self.stop_index = 1\n",
        "        return words\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.corpus)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return (torch.tensor(self.input_corpus_indexes[index], device=self.device),\n",
        "            torch.tensor(self.output_corpus_indexes[index], device=self.device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbZkeW_cFeQW",
        "outputId": "2599f145-3929-4ecf-e35c-81df70d0e0cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU is available\n"
          ]
        }
      ],
      "source": [
        "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, CPU used\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qDc7AlZEFeQ0"
      },
      "outputs": [],
      "source": [
        "def pad_collate(data):\n",
        "    def left_pad_sequence(tensors):\n",
        "        max_len = max(list(map(len, tensors)))\n",
        "        padded_seq = [torch.hstack([torch.zeros(max_len - len(t), device=t.device, dtype=torch.int32), t]) for t in tensors]\n",
        "        return torch.stack(padded_seq)\n",
        "\n",
        "\n",
        "    inputs = [d[0] for d in data]\n",
        "    outputs = [d[1] for d in data]\n",
        "    inputs = left_pad_sequence(inputs)\n",
        "    outputs = left_pad_sequence(outputs)\n",
        "    return inputs, outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POBTPy_0FeQ2",
        "outputId": "2a11783e-ea76-4c72-c523-0f57a4c4e2e0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000000/1000000 [00:18<00:00, 53660.23it/s]\n"
          ]
        }
      ],
      "source": [
        "dataset = Dataset(corpus_length = 1000000, device=device)\n",
        "# loader = torch.utils.data.DataLoader(dataset, batch_size=5, collate_fn=pad_collate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "555120"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dataset.unique_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0zGnugNFeQ3"
      },
      "outputs": [],
      "source": [
        "# for x,y in loader:\n",
        "#     for s_in, s_out in zip(x,y):\n",
        "#         print(dataset.indexes_to_sentence([x.item() for x in s_out]))\n",
        "#     print('-----------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQ1h3CT1FeQ5",
        "outputId": "f89c7257-e8df-481d-85e4-c2bcae583458"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10472914944, 15843721216)\n",
            "4005144064\n",
            "4022337536\n"
          ]
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "print(torch.cuda.memory.mem_get_info())\n",
        "print(torch.cuda.memory_allocated())\n",
        "print(torch.cuda.memory_reserved())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xGVwZGZFeQ6",
        "outputId": "274ee721-7ace-45ca-fc40-137071536057"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RNN(\n",
              "  (embedding): Embedding(791020, 100, padding_idx=0)\n",
              "  (rnn): RNN(100, 128, num_layers=2, batch_first=True)\n",
              "  (fc): Linear(in_features=128, out_features=791020, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, dataset, device, embedding_dim=100, hidden_size = 128, num_layers = 2):\n",
        "        super(RNN, self).__init__()\n",
        "        self.device = device\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        \n",
        "        n_vocab = len(dataset.unique_words)\n",
        "\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=n_vocab,\n",
        "            embedding_dim=embedding_dim,\n",
        "            padding_idx=0\n",
        "        )\n",
        "\n",
        "        self.rnn = nn.RNN(input_size=embedding_dim, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_size, n_vocab)\n",
        "\n",
        "    def forward(self, x, h0 = None):\n",
        "\n",
        "        x.to(self.device)\n",
        "\n",
        "        embed = self.embedding(x)\n",
        "\n",
        "        if h0 == None:\n",
        "            h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size, device=self.device)\n",
        "\n",
        "        output, state = self.rnn(embed, h0)\n",
        "        \n",
        "        logits = self.fc(output)\n",
        "\n",
        "        return logits, state\n",
        "\n",
        "\n",
        "        \n",
        "model = RNN(dataset, device) \n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzANOaAlFeQ7",
        "outputId": "be93171a-02ba-40ac-e60f-17ecb52f7be4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(9749397504, 15843721216)\n",
            "4730230272\n",
            "4745854976\n"
          ]
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "print(torch.cuda.memory.mem_get_info())\n",
        "print(torch.cuda.memory_allocated())\n",
        "print(torch.cuda.memory_reserved())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqZKAdjwFeQ8"
      },
      "outputs": [],
      "source": [
        "# model.load_state_dict(torch.load('./models/RNN_30ep.model'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6KwXbBbFeQ8",
        "outputId": "52d55caa-2ba3-44bf-cbc4-7760d25d96ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'batch': 0, 'loss': 13.635276794433594}\n",
            "{'epoch': 0, 'batch': 500, 'loss': 3.255164623260498}\n",
            "{'epoch': 0, 'batch': 1000, 'loss': 4.356067657470703}\n",
            "{'epoch': 0, 'batch': 1500, 'loss': 2.247701644897461}\n",
            "{'epoch': 0, 'batch': 2000, 'loss': 6.966792583465576}\n",
            "{'epoch': 0, 'batch': 2500, 'loss': 6.141841411590576}\n",
            "{'epoch': 0, 'batch': 3000, 'loss': 4.814615249633789}\n",
            "{'epoch': 0, 'batch': 3500, 'loss': 5.683190822601318}\n",
            "{'epoch': 0, 'batch': 4000, 'loss': 5.349299907684326}\n",
            "{'epoch': 0, 'batch': 4500, 'loss': 6.729761123657227}\n",
            "{'epoch': 0, 'batch': 5000, 'loss': 7.206076622009277}\n",
            "{'epoch': 0, 'batch': 5500, 'loss': 7.208861827850342}\n",
            "{'epoch': 0, 'batch': 6000, 'loss': 5.900472164154053}\n",
            "{'epoch': 0, 'batch': 6500, 'loss': 7.412659168243408}\n",
            "{'epoch': 0, 'batch': 7000, 'loss': 6.269425868988037}\n",
            "{'epoch': 0, 'batch': 7500, 'loss': 7.001075744628906}\n",
            "{'epoch': 0, 'batch': 8000, 'loss': 6.401076316833496}\n",
            "{'epoch': 0, 'batch': 8500, 'loss': 7.095688343048096}\n",
            "{'epoch': 0, 'batch': 9000, 'loss': 7.906700611114502}\n",
            "{'epoch': 0, 'batch': 9500, 'loss': 6.356646537780762}\n",
            "{'epoch': 0, 'batch': 10000, 'loss': 5.5306549072265625}\n",
            "{'epoch': 0, 'batch': 10500, 'loss': 8.09002685546875}\n",
            "{'epoch': 0, 'batch': 11000, 'loss': 6.75668478012085}\n",
            "{'epoch': 0, 'batch': 11500, 'loss': 7.298702239990234}\n",
            "{'epoch': 0, 'batch': 12000, 'loss': 7.306758403778076}\n",
            "{'epoch': 0, 'batch': 12500, 'loss': 6.3601765632629395}\n",
            "{'epoch': 0, 'batch': 13000, 'loss': 6.799030303955078}\n",
            "{'epoch': 0, 'batch': 13500, 'loss': 7.2575836181640625}\n",
            "{'epoch': 0, 'batch': 14000, 'loss': 7.7984442710876465}\n",
            "{'epoch': 0, 'batch': 14500, 'loss': 6.7197699546813965}\n",
            "{'epoch': 0, 'batch': 15000, 'loss': 6.368382930755615}\n",
            "{'epoch': 0, 'batch': 15500, 'loss': 7.828752040863037}\n",
            "{'epoch': 0, 'batch': 16000, 'loss': 7.727849006652832}\n",
            "{'epoch': 0, 'batch': 16500, 'loss': 7.956652641296387}\n",
            "{'epoch': 0, 'batch': 17000, 'loss': 8.033333778381348}\n",
            "{'epoch': 0, 'batch': 17500, 'loss': 8.372885704040527}\n",
            "{'epoch': 0, 'batch': 18000, 'loss': 7.390357971191406}\n",
            "{'epoch': 0, 'batch': 18500, 'loss': 8.553961753845215}\n",
            "{'epoch': 0, 'batch': 19000, 'loss': 7.486841678619385}\n",
            "{'epoch': 0, 'batch': 19500, 'loss': 6.337649345397949}\n",
            "{'epoch': 0, 'batch': 20000, 'loss': 7.095290660858154}\n",
            "{'epoch': 0, 'batch': 20500, 'loss': 7.487037658691406}\n",
            "{'epoch': 0, 'batch': 21000, 'loss': 8.243282318115234}\n",
            "{'epoch': 0, 'batch': 21500, 'loss': 8.215048789978027}\n",
            "{'epoch': 0, 'batch': 22000, 'loss': 7.665736198425293}\n",
            "{'epoch': 0, 'batch': 22500, 'loss': 7.095214366912842}\n",
            "{'epoch': 0, 'batch': 23000, 'loss': 7.074795722961426}\n",
            "{'epoch': 0, 'batch': 23500, 'loss': 7.281445503234863}\n",
            "{'epoch': 0, 'batch': 24000, 'loss': 6.736027717590332}\n",
            "{'epoch': 0, 'batch': 24500, 'loss': 7.9546895027160645}\n",
            "{'epoch': 0, 'batch': 25000, 'loss': 7.805078029632568}\n",
            "{'epoch': 0, 'batch': 25500, 'loss': 7.939788341522217}\n",
            "{'epoch': 0, 'batch': 26000, 'loss': 7.2270708084106445}\n",
            "{'epoch': 0, 'batch': 26500, 'loss': 7.9237213134765625}\n",
            "{'epoch': 0, 'batch': 27000, 'loss': 7.590060234069824}\n",
            "{'epoch': 0, 'batch': 27500, 'loss': 6.4911932945251465}\n",
            "{'epoch': 0, 'batch': 28000, 'loss': 7.0599894523620605}\n",
            "{'epoch': 0, 'batch': 28500, 'loss': 7.200048446655273}\n",
            "{'epoch': 0, 'batch': 29000, 'loss': 7.290501594543457}\n",
            "{'epoch': 0, 'batch': 29500, 'loss': 7.3469038009643555}\n",
            "{'epoch': 0, 'batch': 30000, 'loss': 7.677979946136475}\n",
            "{'epoch': 0, 'batch': 30500, 'loss': 7.252872943878174}\n",
            "{'epoch': 0, 'batch': 31000, 'loss': 7.706902980804443}\n",
            "{'epoch': 0, 'batch': 31500, 'loss': 7.327611923217773}\n",
            "{'epoch': 0, 'batch': 32000, 'loss': 8.552967071533203}\n",
            "{'epoch': 0, 'batch': 32500, 'loss': 7.567269802093506}\n",
            "{'epoch': 0, 'batch': 33000, 'loss': 6.975244045257568}\n",
            "{'epoch': 0, 'batch': 33500, 'loss': 7.5260701179504395}\n",
            "{'epoch': 0, 'batch': 34000, 'loss': 6.809125900268555}\n",
            "{'epoch': 0, 'batch': 34500, 'loss': 7.204383373260498}\n",
            "{'epoch': 0, 'batch': 35000, 'loss': 6.558028697967529}\n",
            "{'epoch': 0, 'batch': 35500, 'loss': 7.229639053344727}\n",
            "{'epoch': 0, 'batch': 36000, 'loss': 7.387023448944092}\n",
            "{'epoch': 0, 'batch': 36500, 'loss': 7.193686485290527}\n",
            "{'epoch': 0, 'batch': 37000, 'loss': 7.790442943572998}\n",
            "{'epoch': 0, 'batch': 37500, 'loss': 6.876572608947754}\n",
            "{'epoch': 0, 'batch': 38000, 'loss': 7.1444878578186035}\n",
            "{'epoch': 0, 'batch': 38500, 'loss': 6.696192741394043}\n",
            "{'epoch': 0, 'batch': 39000, 'loss': 6.837015151977539}\n",
            "{'epoch': 0, 'batch': 39500, 'loss': 6.8835039138793945}\n",
            "{'epoch': 0, 'batch': 40000, 'loss': 8.469794273376465}\n",
            "{'epoch': 0, 'batch': 40500, 'loss': 6.853333473205566}\n",
            "{'epoch': 0, 'batch': 41000, 'loss': 7.6020827293396}\n",
            "{'epoch': 0, 'batch': 41500, 'loss': 7.726797580718994}\n",
            "{'epoch': 0, 'batch': 42000, 'loss': 7.951786994934082}\n",
            "{'epoch': 0, 'batch': 42500, 'loss': 6.947436332702637}\n",
            "{'epoch': 0, 'batch': 43000, 'loss': 7.655358791351318}\n",
            "{'epoch': 0, 'batch': 43500, 'loss': 7.103872299194336}\n",
            "{'epoch': 0, 'batch': 44000, 'loss': 6.953047275543213}\n",
            "{'epoch': 0, 'batch': 44500, 'loss': 8.510955810546875}\n",
            "{'epoch': 0, 'batch': 45000, 'loss': 7.86649751663208}\n",
            "{'epoch': 0, 'batch': 45500, 'loss': 7.489266872406006}\n",
            "{'epoch': 0, 'batch': 46000, 'loss': 7.261523246765137}\n",
            "{'epoch': 0, 'batch': 46500, 'loss': 7.667969226837158}\n",
            "{'epoch': 0, 'batch': 47000, 'loss': 8.509123802185059}\n",
            "{'epoch': 0, 'batch': 47500, 'loss': 7.721804141998291}\n",
            "{'epoch': 0, 'batch': 48000, 'loss': 8.179980278015137}\n",
            "{'epoch': 0, 'batch': 48500, 'loss': 7.248722076416016}\n",
            "{'epoch': 0, 'batch': 49000, 'loss': 7.1291680335998535}\n",
            "{'epoch': 0, 'batch': 49500, 'loss': 7.608700275421143}\n",
            "{'epoch': 0, 'batch': 50000, 'loss': 8.033187866210938}\n",
            "{'epoch': 0, 'batch': 50500, 'loss': 7.520817279815674}\n",
            "{'epoch': 0, 'batch': 51000, 'loss': 7.645412921905518}\n",
            "{'epoch': 0, 'batch': 51500, 'loss': 8.056406021118164}\n",
            "{'epoch': 0, 'batch': 52000, 'loss': 7.6283063888549805}\n",
            "{'epoch': 0, 'batch': 52500, 'loss': 7.3103156089782715}\n",
            "{'epoch': 0, 'batch': 53000, 'loss': 7.150959491729736}\n",
            "{'epoch': 0, 'batch': 53500, 'loss': 7.835352420806885}\n"
          ]
        }
      ],
      "source": [
        "def train(dataset, model, max_epochs = 30, batch_size = 20):\n",
        "    model.train()\n",
        "\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, collate_fn=pad_collate)\n",
        "    \n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(max_epochs):        \n",
        "        for batch, (x, y) in enumerate(dataloader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            y_pred, _ = model(x)\n",
        "            loss = criterion(y_pred.transpose(1, 2), y)\n",
        "            \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if batch % 500 == 0:\n",
        "                print({ 'epoch': epoch, 'batch': batch, 'loss': loss.item() })\n",
        "                torch.cuda.empty_cache()\n",
        "        \n",
        "        if (epoch+1) % 5 == 0:\n",
        "            torch.save(model.state_dict(), f\"./models/RNN_2000000_{epoch+1}ep.model\")\n",
        "            \n",
        "train(dataset, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4FjhkcOFeQ9"
      },
      "outputs": [],
      "source": [
        "# torch.save(model.state_dict(), './models/RNN_60ep.model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_h2MTY7FeQ9"
      },
      "outputs": [],
      "source": [
        "def predict(dataset, model, text, next_words=100):\n",
        "    model.eval()\n",
        "\n",
        "    words = text.split(' ')\n",
        "    \n",
        "    for i in range(0, next_words):\n",
        "        x = torch.tensor([[dataset.word_to_index[w] for w in words]], device=model.device)\n",
        "        y_pred, _ = model(x)\n",
        "\n",
        "        # print(y_pred)\n",
        "\n",
        "        last_word_logits = y_pred[0][-1]\n",
        "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().cpu().numpy()\n",
        "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
        "        words.append(dataset.index_to_word[word_index])\n",
        "\n",
        "    return words\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lw-CThdoFeQ_"
      },
      "outputs": [],
      "source": [
        "def predict_2(dataset, model, text, next_words=100):\n",
        "    model.eval()\n",
        "\n",
        "    words = text.split(' ')\n",
        "\n",
        "    x = torch.tensor([[dataset.word_to_index[w] for w in words]], device=model.device)\n",
        "    y_pred, hidden_state = model(x)\n",
        "    \n",
        "    for i in range(0, next_words):\n",
        "        last_word_logits = y_pred[0][-1]\n",
        "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().cpu().numpy()\n",
        "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
        "        words.append(dataset.index_to_word[word_index])\n",
        "\n",
        "        y_pred, hidden_state = model(torch.tensor([[word_index]], device=model.device), hidden_state)\n",
        "\n",
        "    return words\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6PYBzHSFeQ_",
        "outputId": "01f09b3e-c4bb-4727-f882-6e7f448d4179"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['świadkowie',\n",
              " 'zdarzenia',\n",
              " 'sfotografowali',\n",
              " 'sprawcę',\n",
              " 'podczas',\n",
              " 'gwałtu',\n",
              " 'i',\n",
              " 'powiadomili',\n",
              " 'policję',\n",
              " 'która',\n",
              " 'schwytała',\n",
              " 'go',\n",
              " 'kilka',\n",
              " 'godzin',\n",
              " 'później',\n",
              " '<STOP>']"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict_2(dataset, model, \"świadkowie\", next_words=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7s4nqL3DFeRA"
      },
      "outputs": [],
      "source": [
        "# def best_logits(logits, n):\n",
        "\n",
        "\n",
        "def beam_search(dataset, model, text, max_next_words, n_solutions):\n",
        "    model.eval()\n",
        "\n",
        "    words = text.split(' ')\n",
        "\n",
        "    x = torch.tensor([[dataset.word_to_index[w] for w in words]], device=model.device)\n",
        "\n",
        "    y_pred, hidden_state = model(x)\n",
        "    last_word_logits = y_pred[0][-1]\n",
        "    log_p = torch.nn.functional.log_softmax(last_word_logits, dim=0).detach().cpu().numpy()\n",
        "\n",
        "    best_indices = np.argsort(log_p)[::-1][:n_solutions]\n",
        "\n",
        "    solutions = [([index], log_p[index], hidden_state) for index in best_indices]\n",
        "\n",
        "    for i in range(1, max_next_words):\n",
        "        new_solutions = []\n",
        "\n",
        "        for (prefix, score, prefix_state) in solutions:\n",
        "            x = torch.tensor([[prefix[-1]]], device=model.device)\n",
        "            y_pred, hi = model(x, prefix_state)\n",
        "            last_word_logits = y_pred[0][-1]\n",
        "            log_p = torch.nn.functional.log_softmax(last_word_logits, dim=0).detach().cpu().numpy()\n",
        "            best_indices = np.argsort(log_p)[::-1][:n_solutions]\n",
        "            new_solutions += [(prefix + [ind], score + log_p[ind], hi) for ind in best_indices]\n",
        "\n",
        "        best_indices = np.argsort([score for (_, score, _) in new_solutions])[::-1][:n_solutions]\n",
        "\n",
        "        solutions = [new_solutions[ind] for ind in best_indices]\n",
        "\n",
        "    return [([dataset.index_to_word[w] for w in sent], lp) for (sent, lp, _) in solutions]\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QOcZ-ARwFeRB",
        "outputId": "1cf614d6-1ad1-49f4-ad2f-29f4e124ec55"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(['zdarzenia', 'sfotografowali', 'sprawcę'], -0.000649821),\n",
              " (['zdarzenia', 'sfotografowali', 'w'], -8.26417),\n",
              " (['zdarzenia', 'sfotografowali', 'uczniów'], -9.916093)]"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "beam_search(dataset, model, \"świadkowie\", max_next_words=3, n_solutions=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDxo3-GrFeRB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "RNN.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
