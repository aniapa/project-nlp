{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EOL0AvaDFeQP"
      },
      "outputs": [],
      "source": [
        "import gensim.utils as utils\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "from nltk.tokenize import word_tokenize\n",
        "import sentencepiece as spm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mlV7Z8NHFeQU"
      },
      "outputs": [],
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, corpus_length = None, device = None, corpus_path = './data/train_shuf.txt'):\n",
        "        corpus_file = open(corpus_path)\n",
        "\n",
        "        if device == None:\n",
        "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "        if corpus_length == None:\n",
        "            corpus_length = sum(1 for line in corpus_file)\n",
        "            corpus_file.seek(0)\n",
        "        \n",
        "        self.corpus = []\n",
        "\n",
        "        for i in tqdm(range(corpus_length)):\n",
        "            self.corpus.append(utils.simple_preprocess(corpus_file.readline(), min_len=1))\n",
        "            # self.corpus.append(word_tokenize(corpus_file.readline().lower()))\n",
        "\n",
        "        self.corpus = sorted(self.corpus, key=lambda x: len(x))\n",
        "        \n",
        "        self.unique_words = self.get_unique_words()\n",
        "\n",
        "        self.index_to_word = {index: word for index, word in enumerate(self.unique_words)}\n",
        "        self.word_to_index = {word: index for index, word in enumerate(self.unique_words)}\n",
        "\n",
        "        self.input_corpus_indexes = [list(map(lambda word: self.word_to_index[word], sentence)) for sentence in self.corpus]\n",
        "        output_corpus = [sentence[1:] + ['<STOP>'] for sentence in self.corpus]\n",
        "\n",
        "        self.output_corpus_indexes = [list(map(lambda word: self.word_to_index[word], sentence)) for sentence in output_corpus]\n",
        "        \n",
        "        self.device = device\n",
        "\n",
        "\n",
        "    def indexes_to_sentence(self, sentence):\n",
        "        return list(map(lambda x: self.index_to_word[x], sentence))\n",
        "\n",
        "\n",
        "    def get_unique_words(self):\n",
        "        words = list(set([word for line in self.corpus for word in line]))\n",
        "        words.sort()\n",
        "        words = ['<PAD>', '<STOP>'] + words\n",
        "        self.pad_index = 0\n",
        "        self.stop_index = 1\n",
        "        return words\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.corpus)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return (torch.tensor(self.input_corpus_indexes[index], device=self.device),\n",
        "            torch.tensor(self.output_corpus_indexes[index], device=self.device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbZkeW_cFeQW",
        "outputId": "2599f145-3929-4ecf-e35c-81df70d0e0cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU is available\n"
          ]
        }
      ],
      "source": [
        "# torch.cuda.is_available() checks and returns a Boolean True if a GPU is available, else it'll return False\n",
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, CPU used\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qDc7AlZEFeQ0"
      },
      "outputs": [],
      "source": [
        "def pad_collate(data):\n",
        "    def left_pad_sequence(tensors):\n",
        "        max_len = max(list(map(len, tensors)))\n",
        "        padded_seq = [torch.hstack([torch.zeros(max_len - len(t), device=t.device, dtype=torch.int32), t]) for t in tensors]\n",
        "        return torch.stack(padded_seq)\n",
        "\n",
        "\n",
        "    inputs = [d[0] for d in data]\n",
        "    outputs = [d[1] for d in data]\n",
        "    inputs = left_pad_sequence(inputs)\n",
        "    outputs = left_pad_sequence(outputs)\n",
        "    return inputs, outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POBTPy_0FeQ2",
        "outputId": "2a11783e-ea76-4c72-c523-0f57a4c4e2e0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 40230.04it/s]\n"
          ]
        }
      ],
      "source": [
        "dataset = Dataset(corpus_length = 1000, device=device)\n",
        "# loader = torch.utils.data.DataLoader(dataset, batch_size=5, collate_fn=pad_collate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "555120"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dataset.unique_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0zGnugNFeQ3"
      },
      "outputs": [],
      "source": [
        "# for x,y in loader:\n",
        "#     for s_in, s_out in zip(x,y):\n",
        "#         print(dataset.indexes_to_sentence([x.item() for x in s_out]))\n",
        "#     print('-----------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQ1h3CT1FeQ5",
        "outputId": "f89c7257-e8df-481d-85e4-c2bcae583458"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10472914944, 15843721216)\n",
            "4005144064\n",
            "4022337536\n"
          ]
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "print(torch.cuda.memory.mem_get_info())\n",
        "print(torch.cuda.memory_allocated())\n",
        "print(torch.cuda.memory_reserved())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xGVwZGZFeQ6",
        "outputId": "274ee721-7ace-45ca-fc40-137071536057"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RNN(\n",
              "  (embedding): Embedding(7845, 100, padding_idx=0)\n",
              "  (rnn): RNN(100, 128, num_layers=2, batch_first=True)\n",
              "  (fc): Linear(in_features=128, out_features=7845, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, dataset, device, embedding_dim=100, hidden_size = 128, num_layers = 2):\n",
        "        super(RNN, self).__init__()\n",
        "        self.device = device\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        \n",
        "        n_vocab = len(dataset.unique_words)\n",
        "\n",
        "        self.embedding = nn.Embedding(\n",
        "            num_embeddings=n_vocab,\n",
        "            embedding_dim=embedding_dim,\n",
        "            padding_idx=0\n",
        "        )\n",
        "\n",
        "        self.rnn = nn.RNN(input_size=embedding_dim, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n",
        "\n",
        "        self.fc = nn.Linear(hidden_size, n_vocab)\n",
        "\n",
        "    def forward(self, x, h0 = None):\n",
        "\n",
        "        x.to(self.device)\n",
        "\n",
        "        embed = self.embedding(x)\n",
        "\n",
        "        if h0 == None:\n",
        "            if len(x.shape) == 2:\n",
        "                h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size, device=self.device)\n",
        "            else:\n",
        "                h0 = torch.zeros(self.num_layers, self.hidden_size, device = self.device)\n",
        "                \n",
        "        output, state = self.rnn(embed, h0)\n",
        "        \n",
        "        logits = self.fc(output)\n",
        "\n",
        "        return logits, state\n",
        "\n",
        "\n",
        "        \n",
        "model = RNN(dataset, device) \n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzANOaAlFeQ7",
        "outputId": "be93171a-02ba-40ac-e60f-17ecb52f7be4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(9749397504, 15843721216)\n",
            "4730230272\n",
            "4745854976\n"
          ]
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "print(torch.cuda.memory.mem_get_info())\n",
        "print(torch.cuda.memory_allocated())\n",
        "print(torch.cuda.memory_reserved())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sqZKAdjwFeQ8"
      },
      "outputs": [],
      "source": [
        "# model.load_state_dict(torch.load('./models/RNN_30ep.model'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6KwXbBbFeQ8",
        "outputId": "52d55caa-2ba3-44bf-cbc4-7760d25d96ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'epoch': 0, 'batch': 0, 'loss': 8.936690330505371}\n",
            "{'epoch': 1, 'batch': 0, 'loss': 6.936734676361084}\n",
            "{'epoch': 2, 'batch': 0, 'loss': 6.408848285675049}\n",
            "{'epoch': 3, 'batch': 0, 'loss': 5.959949970245361}\n",
            "{'epoch': 4, 'batch': 0, 'loss': 5.3872785568237305}\n",
            "{'epoch': 5, 'batch': 0, 'loss': 4.842416286468506}\n",
            "{'epoch': 6, 'batch': 0, 'loss': 4.332563400268555}\n",
            "{'epoch': 7, 'batch': 0, 'loss': 3.8785059452056885}\n",
            "{'epoch': 8, 'batch': 0, 'loss': 3.4727783203125}\n",
            "{'epoch': 9, 'batch': 0, 'loss': 3.0714962482452393}\n",
            "{'epoch': 10, 'batch': 0, 'loss': 2.7132012844085693}\n",
            "{'epoch': 11, 'batch': 0, 'loss': 2.337073564529419}\n",
            "{'epoch': 12, 'batch': 0, 'loss': 1.961910367012024}\n",
            "{'epoch': 13, 'batch': 0, 'loss': 1.6408451795578003}\n",
            "{'epoch': 14, 'batch': 0, 'loss': 1.3666863441467285}\n",
            "{'epoch': 15, 'batch': 0, 'loss': 1.1355453729629517}\n",
            "{'epoch': 16, 'batch': 0, 'loss': 0.9429917931556702}\n",
            "{'epoch': 17, 'batch': 0, 'loss': 0.7863861918449402}\n",
            "{'epoch': 18, 'batch': 0, 'loss': 0.6634930372238159}\n",
            "{'epoch': 19, 'batch': 0, 'loss': 0.5681917667388916}\n",
            "{'epoch': 20, 'batch': 0, 'loss': 0.49207016825675964}\n",
            "{'epoch': 21, 'batch': 0, 'loss': 0.43186020851135254}\n",
            "{'epoch': 22, 'batch': 0, 'loss': 0.38676005601882935}\n",
            "{'epoch': 23, 'batch': 0, 'loss': 0.35612109303474426}\n",
            "{'epoch': 24, 'batch': 0, 'loss': 0.3272583782672882}\n",
            "{'epoch': 25, 'batch': 0, 'loss': 0.29906806349754333}\n",
            "{'epoch': 26, 'batch': 0, 'loss': 0.27253422141075134}\n",
            "{'epoch': 27, 'batch': 0, 'loss': 0.25173088908195496}\n",
            "{'epoch': 28, 'batch': 0, 'loss': 0.2344505935907364}\n",
            "{'epoch': 29, 'batch': 0, 'loss': 0.21982289850711823}\n"
          ]
        }
      ],
      "source": [
        "def train(dataset, model, max_epochs = 30, batch_size = 20):\n",
        "    model.train()\n",
        "\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, collate_fn=pad_collate)\n",
        "    \n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(max_epochs):        \n",
        "        for batch, (x, y) in enumerate(dataloader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            y_pred, _ = model(x)\n",
        "            loss = criterion(y_pred.transpose(1, 2), y)\n",
        "            \n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if batch % 500 == 0:\n",
        "                print({ 'epoch': epoch, 'batch': batch, 'loss': loss.item() })\n",
        "                torch.cuda.empty_cache()\n",
        "        \n",
        "        if (epoch+1) % 5 == 0:\n",
        "            torch.save(model.state_dict(), f\"./models/RNN_2000000_{epoch+1}ep.model\")\n",
        "            \n",
        "train(dataset, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4FjhkcOFeQ9"
      },
      "outputs": [],
      "source": [
        "# torch.save(model.state_dict(), './models/RNN_60ep.model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lw-CThdoFeQ_"
      },
      "outputs": [],
      "source": [
        "def predict(dataset, model, text, next_words=100):\n",
        "    model.eval()\n",
        "\n",
        "    words = text.split(' ')\n",
        "\n",
        "    x = torch.tensor([[dataset.word_to_index[w] for w in words]], device=model.device)\n",
        "    y_pred, hidden_state = model(x)\n",
        "    \n",
        "    for i in range(0, next_words):\n",
        "        last_word_logits = y_pred[0][-1]\n",
        "        p = torch.nn.functional.softmax(last_word_logits, dim=0).detach().cpu().numpy()\n",
        "        word_index = np.random.choice(len(last_word_logits), p=p)\n",
        "        words.append(dataset.index_to_word[word_index])\n",
        "\n",
        "        y_pred, hidden_state = model(torch.tensor([[word_index]], device=model.device), hidden_state)\n",
        "\n",
        "    return words\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_6PYBzHSFeQ_",
        "outputId": "01f09b3e-c4bb-4727-f882-6e7f448d4179"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['świadkowie',\n",
              " 'z',\n",
              " 'oprawców',\n",
              " 'społecznymi',\n",
              " 'historii',\n",
              " 'ministra',\n",
              " 'rosyjskich',\n",
              " 'dwóch',\n",
              " 'ustawy',\n",
              " 'było',\n",
              " 'na',\n",
              " 'łączenie',\n",
              " 'coś',\n",
              " '<STOP>',\n",
              " 'nie',\n",
              " 'będą']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict_2(dataset, model, \"świadkowie\", next_words=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "7s4nqL3DFeRA"
      },
      "outputs": [],
      "source": [
        "# def best_logits(logits, n):\n",
        "\n",
        "\n",
        "def beam_search(dataset, model, text, next_words, n_solutions):\n",
        "    model.eval()\n",
        "\n",
        "    words = text.split(' ')\n",
        "\n",
        "    x = torch.tensor([[dataset.word_to_index[w] for w in words]], device=model.device)\n",
        "\n",
        "    y_pred, hidden_state = model(x)\n",
        "    last_word_logits = y_pred[0][-1]\n",
        "    log_p = torch.nn.functional.log_softmax(last_word_logits, dim=0).detach().cpu().numpy()\n",
        "\n",
        "    best_indices = np.argsort(log_p)[::-1][:n_solutions]\n",
        "\n",
        "    solutions = [([index], log_p[index], hidden_state) for index in best_indices]\n",
        "\n",
        "    for i in range(1, next_words):\n",
        "        new_solutions = []\n",
        "\n",
        "        for (prefix, score, prefix_state) in solutions:\n",
        "            x = torch.tensor([[prefix[-1]]], device=model.device)\n",
        "            y_pred, hi = model(x, prefix_state)\n",
        "            last_word_logits = y_pred[0][-1]\n",
        "            log_p = torch.nn.functional.log_softmax(last_word_logits, dim=0).detach().cpu().numpy()\n",
        "            best_indices = np.argsort(log_p)[::-1][:n_solutions]\n",
        "            new_solutions += [(prefix + [ind], score + log_p[ind], hi) for ind in best_indices]\n",
        "\n",
        "        best_indices = np.argsort([score for (_, score, _) in new_solutions])[::-1][:n_solutions]\n",
        "\n",
        "        solutions = [new_solutions[ind] for ind in best_indices]\n",
        "\n",
        "    return [' '.join(words + [dataset.index_to_word[w] for w in sent]) for (sent, _, _) in solutions]\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "QOcZ-ARwFeRB",
        "outputId": "1cf614d6-1ad1-49f4-ad2f-29f4e124ec55"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['książka zawiera również rozdział traktujący o stresie zawodowym personelu więziennego oraz aktualnych trendach',\n",
              " 'książka zawiera również rozdział traktujący o stresie zawodowym personelu więziennego się od głosu',\n",
              " 'książka zawiera również rozdział traktujący o stresie zawodowym personelu więziennego to jest już',\n",
              " 'książka zawiera również rozdział traktujący o stresie zawodowym personelu więziennego się z polityki',\n",
              " 'książka zawiera również rozdział traktujący o stresie zawodowym personelu więziennego się przez cały',\n",
              " 'książka zawiera również rozdział traktujący o stresie zawodowym personelu więziennego to może być',\n",
              " 'książka zawiera również rozdział traktujący o stresie zawodowym personelu więziennego nie ma być',\n",
              " 'książka zawiera również rozdział traktujący o stresie zawodowym personelu więziennego się z radości',\n",
              " 'książka zawiera również rozdział traktujący o stresie zawodowym personelu więziennego się na bardziej',\n",
              " 'książka zawiera również rozdział traktujący o stresie zawodowym personelu więziennego się od głosowania']"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#RNN with word tokenization\n",
        "beam_search(dataset, model, \"książka zawiera również\", next_words=10, n_solutions=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "dDxo3-GrFeRB"
      },
      "outputs": [],
      "source": [
        "def perplexity(dataset, model):\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        criterion = nn.CrossEntropyLoss(reduction='sum')\n",
        "\n",
        "        logs_sum = 0\n",
        "        n_samples = 0\n",
        "        \n",
        "        for x,y in dataset:\n",
        "            y_pred, _ = model(x)\n",
        "            n_samples += len(x)\n",
        "            logs_sum  += criterion(y_pred, y)\n",
        "\n",
        "        return np.exp(logs_sum.item() / n_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "perplexity(dataset, model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "RNN.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
